{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\qwer9\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\gym\\envs\\registration.py:307: DeprecationWarning: The package name gym_minigrid has been deprecated in favor of minigrid. Please uninstall gym_minigrid and install minigrid with `pip install minigrid`. Future releases will be maintained under the new package name minigrid.\n",
      "  fn()\n"
     ]
    }
   ],
   "source": [
    "# Remember to adjust your student ID in meta.xml\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import gym\n",
    "from simple_custom_taxi_env import SimpleTaxiEnv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def table_q_learning(episode = 5000, alpha = 0.1, gamma = 0.99, epsilon_start = 1.0, epsilon_end = 0.1, epsilon_decay = 0.999):\n",
    "#     q_table = {}\n",
    "#     total_rewards = []\n",
    "\n",
    "#     for i in tqdm(range(episode)):\n",
    "#         env = SimpleTaxiEnv(fuel_limit=5000)\n",
    "#         raw_state, _ = env.reset()\n",
    "#         total_reward = 0\n",
    "#         done = False\n",
    "#         step_count = 0\n",
    "#         epsilon = epsilon_start\n",
    "#         taxi_row, taxi_col, _,_,_,_,_,_,_,_,obstacle_north, obstacle_south, obstacle_east, obstacle_west, passenger_look, destination_look = raw_state\n",
    "#         taxi_pos = (taxi_row, taxi_col)\n",
    "#         state = ( obstacle_south, obstacle_north, obstacle_east, obstacle_west)\n",
    "\n",
    "#         saved = False\n",
    "#         # if (i + 1) % 10000 == 0:\n",
    "#         #     saved = True\n",
    "#         #     print(f\"=========================={i+1}th episodes Start!==========================\")\n",
    "        \n",
    "#         while not done:\n",
    "#             if state not in q_table:\n",
    "#                 q_table[state] = np.zeros(6)\n",
    "#             if random.uniform(0, 1) < epsilon:\n",
    "#                 action = random.choice([0, 1, 2, 3, 4, 5])\n",
    "#             else:\n",
    "#                 action = np.argmax(q_table[state])\n",
    "#             next_raw_state, reward, done, _ = env.step(action)\n",
    "\n",
    "#             if saved:\n",
    "#                 env.render_env(taxi_pos, action = action, step = step_count)\n",
    "\n",
    "#             taxi_row, taxi_col, _,_,_,_,_,_,_,_,obstacle_north, obstacle_south, obstacle_east, obstacle_west, passenger_look, destination_look = next_raw_state\n",
    "#             taxi_pos = (taxi_row, taxi_col)\n",
    "#             next_state = ( obstacle_south, obstacle_north, obstacle_east, obstacle_west)\n",
    "#             if next_state not in q_table:\n",
    "#                 q_table[next_state] = np.zeros(6)\n",
    "#             q_table[state][action] = q_table[state][action] + alpha*(reward + gamma*np.max(q_table[next_state]) - q_table[state][action])\n",
    "#             state = next_state\n",
    "#             total_reward += reward\n",
    "#             step_count += 1\n",
    "#             if epsilon > epsilon_end:\n",
    "#                 epsilon *= epsilon_decay\n",
    "#             # if step_count > 500:\n",
    "#             #     break\n",
    "\n",
    "#         total_rewards.append(total_reward)\n",
    "#         if saved:\n",
    "#             print(f\"Episode: {i + 1}/{episode}, Total Reward: {total_reward}, Steps: {step_count}, Epsilon: {epsilon}\")\n",
    "\n",
    "#     return q_table, total_rewards\n",
    "\n",
    "# def save_q_table(q_table):\n",
    "#     with open('q_table.pkl', 'wb') as f:\n",
    "#         pickle.dump(q_table, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_q_learning(episode = 5000, alpha = 0.1, gamma = 0.99, epsilon_start = 1.0, epsilon_end = 0.1, epsilon_decay = 0.999):\n",
    "    q_table = {}\n",
    "    total_rewards = []\n",
    "\n",
    "    for i in tqdm(range(episode)):\n",
    "        env = SimpleTaxiEnv(fuel_limit=5000)\n",
    "        raw_state, _ = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        step_count = 0\n",
    "        epsilon = epsilon_start\n",
    "        taxi_row, taxi_col, R_x, R_y, G_x, G_y, Y_x, Y_y, B_x, B_y, obstacle_north, obstacle_south, obstacle_east, obstacle_west, passenger_look, destination_look = raw_state\n",
    "        taxi_pos = (taxi_row, taxi_col)\n",
    "\n",
    "        station = []\n",
    "        station.append((R_x, R_y))\n",
    "        station.append((G_x, G_y))\n",
    "        station.append((Y_x, Y_y))\n",
    "        station.append((B_x, B_y))\n",
    "\n",
    "        progress = 0\n",
    "        goal = station[progress]\n",
    "        relative_goal_pos = (goal[0] - taxi_row, goal[1] - taxi_col)\n",
    "\n",
    "        state = ( obstacle_south, obstacle_north, obstacle_east, obstacle_west, relative_goal_pos[0], relative_goal_pos[1])\n",
    "\n",
    "        saved = False\n",
    "        # if (i + 1) % 10000 == 0:\n",
    "        #     saved = True\n",
    "        #     print(f\"=========================={i+1}th episodes Start!==========================\")\n",
    "        \n",
    "        while not done:\n",
    "            if state not in q_table:\n",
    "                q_table[state] = np.zeros(6)\n",
    "            if random.uniform(0, 1) < epsilon:\n",
    "                action = random.choice([0, 1, 2, 3, 4, 5])\n",
    "            else:\n",
    "                action = np.argmax(q_table[state])\n",
    "            next_raw_state, reward, done, _ = env.step(action)\n",
    "\n",
    "            if saved:\n",
    "                env.render_env(taxi_pos, action = action, step = step_count)\n",
    "\n",
    "            taxi_row, taxi_col, _,_,_,_,_,_,_,_,obstacle_north, obstacle_south, obstacle_east, obstacle_west, passenger_look, destination_look = next_raw_state\n",
    "\n",
    "            if (taxi_row, taxi_col) == goal:\n",
    "                progress = (progress + 1) % 4\n",
    "                goal = station[progress]\n",
    "                reward += 10\n",
    "            else:\n",
    "                reward -= 0.5 * (abs(taxi_row - goal[0]) + abs(taxi_col - goal[1]))\n",
    "\n",
    "            relative_goal_pos = (goal[0] - taxi_row, goal[1] - taxi_col)\n",
    "            next_state = ( obstacle_south, obstacle_north, obstacle_east, obstacle_west, relative_goal_pos[0], relative_goal_pos[1])\n",
    "\n",
    "            if next_state not in q_table:\n",
    "                q_table[next_state] = np.zeros(6)\n",
    "            q_table[state][action] = q_table[state][action] + alpha*(reward + gamma*np.max(q_table[next_state]) - q_table[state][action])\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            step_count += 1\n",
    "            if epsilon > epsilon_end:\n",
    "                epsilon *= epsilon_decay\n",
    "            # if step_count > 500:\n",
    "            #     break\n",
    "\n",
    "        total_rewards.append(total_reward)\n",
    "        if saved:\n",
    "            print(f\"Episode: {i + 1}/{episode}, Total Reward: {total_reward}, Steps: {step_count}, Epsilon: {epsilon}\")\n",
    "\n",
    "    return q_table, total_rewards\n",
    "\n",
    "def save_q_table(q_table):\n",
    "    with open('q_table.pkl', 'wb') as f:\n",
    "        pickle.dump(q_table, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [04:36<00:00, 18.11it/s]\n"
     ]
    }
   ],
   "source": [
    "q_table, total_rewards = table_q_learning(episode = 5000, alpha = 0.1, gamma = 0.99, epsilon_start = 1.0, epsilon_end = 0.1, epsilon_decay = 0.999)\n",
    "save_q_table(q_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
